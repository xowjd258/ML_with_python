{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_train = torch.FloatTensor(xy[:, 0:-1])\n",
    "# squeeze : 2d->1d\n",
    "y_train = torch.LongTensor(xy[:, [-1]]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 4., 0., 0., 1.]) tensor(0)\n",
      "tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 4., 1., 0., 1.]) tensor(0)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.]) tensor(3)\n",
      "tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 4., 0., 0., 1.]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0, :], y_train[0])\n",
    "print(x_train[1, :], y_train[1])\n",
    "print(x_train[2, :], y_train[2])\n",
    "print(x_train[3, :], y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(16, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.810791 \n",
      "Epoch  100/1000 Cost: 1.222991 \n",
      "Epoch  200/1000 Cost: 0.971313 \n",
      "Epoch  300/1000 Cost: 0.817205 \n",
      "Epoch  400/1000 Cost: 0.714004 \n",
      "Epoch  500/1000 Cost: 0.640063 \n",
      "Epoch  600/1000 Cost: 0.584196 \n",
      "Epoch  700/1000 Cost: 0.540192 \n",
      "Epoch  800/1000 Cost: 0.504375 \n",
      "Epoch  900/1000 Cost: 0.474456 \n",
      "Epoch 1000/1000 Cost: 0.448938 \n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # cost\n",
    "    hypothesis = model(x_train)\n",
    "    cost = F.cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # gradient descent\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # check progress\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.7477, -0.1406, -1.0368,  0.7523, -0.2535, -0.3494, -0.0364,  0.5029,\n",
      "          0.4708,  0.3080, -0.1459, -0.1576,  0.1145,  0.1353,  0.0825,  0.6486],\n",
      "        [-0.0677,  0.8028,  0.2842, -0.3765,  0.4569, -0.2620, -0.0603, -0.6387,\n",
      "          0.2466,  0.1568,  0.0593, -0.3840, -0.1508,  0.5774,  0.0949,  0.2553],\n",
      "        [-0.0516, -0.0624,  0.0441, -0.1485, -0.1357, -0.3067, -0.0057,  0.1042,\n",
      "          0.1894,  0.1823,  0.3353, -0.3243, -0.2362,  0.2487, -0.0964, -0.2570],\n",
      "        [ 0.0018,  0.0187,  0.3793, -0.3161,  0.0714,  0.3134,  0.2509,  0.5267,\n",
      "          0.0873, -0.5986, -0.1529,  0.6871, -0.6751,  0.0270, -0.1860,  0.1070],\n",
      "        [-0.1698, -0.1618, -0.1305, -0.0414,  0.0747,  0.2947,  0.0022,  0.0506,\n",
      "          0.0639, -0.0597,  0.2525, -0.3183,  0.0767, -0.4462, -0.1606, -0.1522],\n",
      "        [ 0.0703, -0.0437, -0.0311,  0.0544,  0.1018, -0.2055, -0.4161, -0.4223,\n",
      "         -0.4983, -0.1888,  0.0767, -0.2806,  0.4747, -0.4888, -0.1334, -0.1631],\n",
      "        [ 0.0218, -0.2067,  0.3637,  0.0246, -0.4038, -0.0457,  0.4441, -0.4389,\n",
      "         -0.6227, -0.5025,  0.0744,  0.0127,  0.2877, -0.2973, -0.1687, -0.0201]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0946,  0.2406, -0.0905,  0.1794, -0.1092, -0.3881, -0.0649],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "W = params[0]\n",
    "b = params[1]\n",
    "print(W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 1, 3, 3, 6, 6, 1, 0, 3, 0, 1, 1, 0, 1,\n",
      "        5, 4, 4, 0, 0, 0, 5, 0, 0, 1, 3, 0, 0, 1, 3, 5, 5, 1, 5, 1, 0, 0, 6, 0,\n",
      "        0, 0, 0, 5, 0, 6, 0, 0, 1, 1, 1, 1, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        5, 3, 0, 0, 3, 3, 1, 1, 3, 1, 3, 1, 0, 6, 3, 1, 5, 4, 1, 0, 3, 0, 0, 1,\n",
      "        0, 5, 0, 1, 1])\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True])\n",
      "Accuracy: 0.9009901285171509\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(x_train)\n",
    "    prediction = torch.argmax(output, 1)\n",
    "    print(prediction)\n",
    "    \n",
    "    correct_prediction = (prediction == y_train)\n",
    "    print(correct_prediction)\n",
    "    \n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
